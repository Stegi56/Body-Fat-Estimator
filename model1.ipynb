{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Imported modules.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "print(\"Imported modules.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set loaded. Num examples:  252\n",
      "Made training and test sets\n"
     ]
    },
    {
     "data": {
      "text/plain": "     Density  BodyFat  Age  Weight  Height  Neck  Chest  Abdomen    Hip  \\\n88      1.08     8.30   46  176.75   72.50 38.00  97.30    86.00  99.30   \n245     1.06    15.20   68  155.50   69.25 36.30  97.40    84.30  94.40   \n81      1.04    26.80   64  150.25   67.25 38.10  97.10    89.00  96.90   \n184     1.06    17.50   40  170.50   74.25 37.70  98.90    90.40  95.50   \n3       1.08    10.40   26  184.75   72.25 37.40 101.80    86.40 101.20   \n..       ...      ...  ...     ...     ...   ...    ...      ...    ...   \n163     1.06    15.10   34  140.00   70.50 36.00  89.20    83.40  89.60   \n90      1.05    20.50   46  177.00   70.00 37.20  99.70    95.60 102.20   \n189     1.04    24.40   41  185.00   68.25 38.00 103.40   101.20 103.10   \n116     1.05    20.10   48  177.25   72.75 36.80  96.00    90.00  99.70   \n149     1.04    25.20   26  223.00   70.25 40.60 114.10   106.80 113.90   \n\n     Thigh  Knee  Ankle  Biceps  Forearm  Wrist  \n88   61.00 38.40  23.80   30.20    29.30  18.80  \n245  54.30 37.50  22.60   29.20    27.30  18.50  \n81   54.80 38.00  22.00   29.90    25.20  17.70  \n184  55.40 38.90  22.40   30.50    28.90  17.70  \n3    60.10 37.30  22.80   32.40    29.40  18.20  \n..     ...   ...    ...     ...      ...    ...  \n163  52.40 35.60  20.40   28.30    26.20  16.50  \n90   58.30 38.20  22.50   29.10    27.70  17.70  \n189  61.50 40.40  22.90   33.40    29.20  18.50  \n116  58.80 38.40  22.80   29.90    28.00  18.10  \n149  67.60 42.70  24.70   36.00    30.40  18.40  \n\n[252 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Density</th>\n      <th>BodyFat</th>\n      <th>Age</th>\n      <th>Weight</th>\n      <th>Height</th>\n      <th>Neck</th>\n      <th>Chest</th>\n      <th>Abdomen</th>\n      <th>Hip</th>\n      <th>Thigh</th>\n      <th>Knee</th>\n      <th>Ankle</th>\n      <th>Biceps</th>\n      <th>Forearm</th>\n      <th>Wrist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>88</th>\n      <td>1.08</td>\n      <td>8.30</td>\n      <td>46</td>\n      <td>176.75</td>\n      <td>72.50</td>\n      <td>38.00</td>\n      <td>97.30</td>\n      <td>86.00</td>\n      <td>99.30</td>\n      <td>61.00</td>\n      <td>38.40</td>\n      <td>23.80</td>\n      <td>30.20</td>\n      <td>29.30</td>\n      <td>18.80</td>\n    </tr>\n    <tr>\n      <th>245</th>\n      <td>1.06</td>\n      <td>15.20</td>\n      <td>68</td>\n      <td>155.50</td>\n      <td>69.25</td>\n      <td>36.30</td>\n      <td>97.40</td>\n      <td>84.30</td>\n      <td>94.40</td>\n      <td>54.30</td>\n      <td>37.50</td>\n      <td>22.60</td>\n      <td>29.20</td>\n      <td>27.30</td>\n      <td>18.50</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>1.04</td>\n      <td>26.80</td>\n      <td>64</td>\n      <td>150.25</td>\n      <td>67.25</td>\n      <td>38.10</td>\n      <td>97.10</td>\n      <td>89.00</td>\n      <td>96.90</td>\n      <td>54.80</td>\n      <td>38.00</td>\n      <td>22.00</td>\n      <td>29.90</td>\n      <td>25.20</td>\n      <td>17.70</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>1.06</td>\n      <td>17.50</td>\n      <td>40</td>\n      <td>170.50</td>\n      <td>74.25</td>\n      <td>37.70</td>\n      <td>98.90</td>\n      <td>90.40</td>\n      <td>95.50</td>\n      <td>55.40</td>\n      <td>38.90</td>\n      <td>22.40</td>\n      <td>30.50</td>\n      <td>28.90</td>\n      <td>17.70</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.08</td>\n      <td>10.40</td>\n      <td>26</td>\n      <td>184.75</td>\n      <td>72.25</td>\n      <td>37.40</td>\n      <td>101.80</td>\n      <td>86.40</td>\n      <td>101.20</td>\n      <td>60.10</td>\n      <td>37.30</td>\n      <td>22.80</td>\n      <td>32.40</td>\n      <td>29.40</td>\n      <td>18.20</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>163</th>\n      <td>1.06</td>\n      <td>15.10</td>\n      <td>34</td>\n      <td>140.00</td>\n      <td>70.50</td>\n      <td>36.00</td>\n      <td>89.20</td>\n      <td>83.40</td>\n      <td>89.60</td>\n      <td>52.40</td>\n      <td>35.60</td>\n      <td>20.40</td>\n      <td>28.30</td>\n      <td>26.20</td>\n      <td>16.50</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>1.05</td>\n      <td>20.50</td>\n      <td>46</td>\n      <td>177.00</td>\n      <td>70.00</td>\n      <td>37.20</td>\n      <td>99.70</td>\n      <td>95.60</td>\n      <td>102.20</td>\n      <td>58.30</td>\n      <td>38.20</td>\n      <td>22.50</td>\n      <td>29.10</td>\n      <td>27.70</td>\n      <td>17.70</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>1.04</td>\n      <td>24.40</td>\n      <td>41</td>\n      <td>185.00</td>\n      <td>68.25</td>\n      <td>38.00</td>\n      <td>103.40</td>\n      <td>101.20</td>\n      <td>103.10</td>\n      <td>61.50</td>\n      <td>40.40</td>\n      <td>22.90</td>\n      <td>33.40</td>\n      <td>29.20</td>\n      <td>18.50</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>1.05</td>\n      <td>20.10</td>\n      <td>48</td>\n      <td>177.25</td>\n      <td>72.75</td>\n      <td>36.80</td>\n      <td>96.00</td>\n      <td>90.00</td>\n      <td>99.70</td>\n      <td>58.80</td>\n      <td>38.40</td>\n      <td>22.80</td>\n      <td>29.90</td>\n      <td>28.00</td>\n      <td>18.10</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>1.04</td>\n      <td>25.20</td>\n      <td>26</td>\n      <td>223.00</td>\n      <td>70.25</td>\n      <td>40.60</td>\n      <td>114.10</td>\n      <td>106.80</td>\n      <td>113.90</td>\n      <td>67.60</td>\n      <td>42.70</td>\n      <td>24.70</td>\n      <td>36.00</td>\n      <td>30.40</td>\n      <td>18.40</td>\n    </tr>\n  </tbody>\n</table>\n<p>252 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataFrame = pd.read_csv(\"bodyfat.csv\")\n",
    "dataFrame = dataFrame.reindex(np.random.permutation(dataFrame.index))\n",
    "\n",
    "print(\"Data set loaded. Num examples: \", len(dataFrame))\n",
    "\n",
    "trainDF = dataFrame.sample(frac = 0.8)\n",
    "testDF = dataFrame.drop(trainDF.index)\n",
    "\n",
    "print(\"Made training and test sets\")\n",
    "\n",
    "dataFrame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing layers defined.\n"
     ]
    }
   ],
   "source": [
    "# Keras Input tensors of float values.\n",
    "inputs = {\n",
    "    'Density':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Density'),\n",
    "    'Age':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Age'),\n",
    "    'Weight':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Weight'),\n",
    "    'Height':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Height'),\n",
    "    'Neck':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Neck'),\n",
    "    'Chest':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Chest'),\n",
    "    'Abdomen':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Abdomen'),\n",
    "    'Hip':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Hip'),\n",
    "    'Thigh':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Thigh'),\n",
    "    'Knee':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Knee'),\n",
    "    'Ankle':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Ankle'),\n",
    "    'Biceps':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Biceps'),\n",
    "    'Forearm':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Forearm'),\n",
    "    'Wrist':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Wrist')\n",
    "}\n",
    "\n",
    "#Normalise\n",
    "density = tf.keras.layers.Normalization(\n",
    "    name='normalization_density',\n",
    "    axis=None)\n",
    "density.adapt(trainDF['Density'])\n",
    "density = density(inputs['Density'])\n",
    "\n",
    "age = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_age',\n",
    "    axis=None)\n",
    "age.adapt(trainDF['Age'])\n",
    "age = age(inputs.get('Age'))\n",
    "\n",
    "weight = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_weight',\n",
    "    axis=None)\n",
    "weight.adapt(trainDF['Weight'])\n",
    "weight = weight(inputs.get('Weight'))\n",
    "\n",
    "height = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_height',\n",
    "    axis=None)\n",
    "height.adapt(trainDF['Height'])\n",
    "height = height(inputs.get('Height'))\n",
    "\n",
    "neck = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_neck',\n",
    "    axis=None)\n",
    "neck.adapt(trainDF['Neck'])\n",
    "neck = neck(inputs.get('Neck'))\n",
    "\n",
    "chest = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_chest',\n",
    "    axis=None)\n",
    "chest.adapt(trainDF['Chest'])\n",
    "chest = chest(inputs.get('Chest'))\n",
    "\n",
    "abdomen = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_abdomen',\n",
    "    axis=None)\n",
    "abdomen.adapt(trainDF['Abdomen'])\n",
    "abdomen = abdomen(inputs.get('Abdomen'))\n",
    "\n",
    "hip = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_hip',\n",
    "    axis=None)\n",
    "hip.adapt(trainDF['Hip'])\n",
    "hip = hip(inputs.get('Hip'))\n",
    "\n",
    "thigh = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_thigh',\n",
    "    axis=None)\n",
    "thigh.adapt(trainDF['Thigh'])\n",
    "thigh = thigh(inputs.get('Thigh'))\n",
    "\n",
    "knee = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_knee',\n",
    "    axis=None)\n",
    "knee.adapt(trainDF['Knee'])\n",
    "knee = knee(inputs.get('Knee'))\n",
    "\n",
    "ankle = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_ankle',\n",
    "    axis=None)\n",
    "ankle.adapt(trainDF['Ankle'])\n",
    "ankle = ankle(inputs.get('Ankle'))\n",
    "\n",
    "biceps = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_biceps',\n",
    "    axis=None)\n",
    "biceps.adapt(trainDF['Biceps'])\n",
    "biceps = biceps(inputs.get('Biceps'))\n",
    "\n",
    "forearm = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_forearm',\n",
    "    axis=None)\n",
    "forearm.adapt(trainDF['Forearm'])\n",
    "forearm = forearm(inputs.get('Forearm'))\n",
    "\n",
    "wrist = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_wrist',\n",
    "    axis=None)\n",
    "wrist.adapt(trainDF['Wrist'])\n",
    "wrist = wrist(inputs.get('Wrist'))\n",
    "\n",
    "# Concatenate our inputs into a single tensor.\n",
    "preprocessing_layers = tf.keras.layers.Concatenate()\n",
    "preprocessing_layers = preprocessing_layers(list(inputs.values()))\n",
    "\n",
    "print(\"Preprocessing layers defined.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the create_model and train_model functions.\n"
     ]
    }
   ],
   "source": [
    "#@title Define functions to create and train a linear regression model\n",
    "def create_model(my_inputs, my_outputs, my_learning_rate):\n",
    "    \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "    model = tf.keras.Model(inputs=my_inputs, outputs=my_outputs)\n",
    "\n",
    "    # Construct the layers into a model that TensorFlow can execute.\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "        learning_rate=my_learning_rate),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create Normalization layers to normalize the median_house_value data.\n",
    "# Because median_house_value is our label (i.e., the target value we're\n",
    "# predicting), these layers won't be added to our model.\n",
    "train_bodyfat_normalized = tf.keras.layers.Normalization(axis=None)\n",
    "train_bodyfat_normalized.adapt(\n",
    "np.array(trainDF['BodyFat']))\n",
    "\n",
    "test_bodyfat_normalized = tf.keras.layers.Normalization(axis=None)\n",
    "test_bodyfat_normalized.adapt(\n",
    "np.array(testDF['BodyFat']))\n",
    "\n",
    "def train_model(model, dataset, epochs, batch_size, label_name, validation_split=0.1):\n",
    "    \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
    "\n",
    "    # Split the dataset into features and label.\n",
    "    features = {name:np.array(value) for name, value in dataset.items()}\n",
    "    label = train_bodyfat_normalized(\n",
    "        np.array(features.pop(label_name)))\n",
    "\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                        epochs=epochs, shuffle=True, validation_split=validation_split, callbacks=[tensorboard_callback])\n",
    "\n",
    "    # Get details that will be useful for plotting the loss curve.\\n\",\n",
    "    epochs = history.epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    mse = hist[\"mean_squared_error\"]\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    return epochs, mse, history.history\n",
    "\n",
    "\n",
    "print(\"Defined the create_model and train_model functions.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "#@title Define linear regression model outputs\n",
    "def get_outputs_linear_regression():\n",
    "    # Create the Dense output layer.\n",
    "    dense_output = tf.keras.layers.Dense(units=1, input_shape=(1,),\n",
    "                                         name='dense_output')(preprocessing_layers)\n",
    "\n",
    "    # Define an output dictionary we'll send to the model constructor.\n",
    "    outputs = {\n",
    "        'dense_output': dense_output\n",
    "    }\n",
    "    return outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "def get_outputs_dnn():\n",
    "    # Create a Dense layer with 20 nodes.\n",
    "    dense_output = tf.keras.layers.Dense(units=13, input_shape=(1,),\n",
    "                                         activation='relu',\n",
    "                                         name='hidden_dense_layer_1')(preprocessing_layers)\n",
    "    # Create a Dense layer with 12 nodes.\n",
    "    dense_output = tf.keras.layers.Dense(units=10, input_shape=(1,),\n",
    "                                         activation='relu',\n",
    "                                         name='hidden_dense_layer_2')(dense_output)\n",
    "    # Create a Dense layer with 12 nodes.\n",
    "    dense_output = tf.keras.layers.Dense(units=7, input_shape=(1,),\n",
    "                                         activation='relu',\n",
    "                                         name='hidden_dense_layer_3')(dense_output)\n",
    "    # Create a Dense layer with 12 nodes.\n",
    "    dense_output = tf.keras.layers.Dense(units=5, input_shape=(1,),\n",
    "                                         activation='relu',\n",
    "                                         name='hidden_dense_layer_4')(dense_output)\n",
    "    # Create a Dense layer with 12 nodes.\n",
    "    dense_output = tf.keras.layers.Dense(units=3, input_shape=(1,),\n",
    "                                         activation='relu',\n",
    "                                         name='hidden_dense_layer_5')(dense_output)\n",
    "    # Create the Dense output layer.\n",
    "    dense_output = tf.keras.layers.Dense(units=1, input_shape=(1,),\n",
    "                                         name='dense_output')(dense_output)\n",
    "\n",
    "    # Define an output dictionary we'll send to the model constructor.\n",
    "    outputs = {\n",
    "        'dense_output': dense_output\n",
    "    }\n",
    "\n",
    "    return outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 2s 67ms/step - loss: 9.5655 - mean_squared_error: 9.5655 - val_loss: 11.8705 - val_mean_squared_error: 11.8705\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 8.0328 - mean_squared_error: 8.0328 - val_loss: 10.2464 - val_mean_squared_error: 10.2464\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 6.8976 - mean_squared_error: 6.8976 - val_loss: 8.8840 - val_mean_squared_error: 8.8840\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 5.9634 - mean_squared_error: 5.9634 - val_loss: 7.7753 - val_mean_squared_error: 7.7753\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 5.2203 - mean_squared_error: 5.2203 - val_loss: 6.8656 - val_mean_squared_error: 6.8656\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 4.6437 - mean_squared_error: 4.6437 - val_loss: 6.0755 - val_mean_squared_error: 6.0755\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 4.1270 - mean_squared_error: 4.1270 - val_loss: 5.3865 - val_mean_squared_error: 5.3865\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 3.6689 - mean_squared_error: 3.6689 - val_loss: 4.9071 - val_mean_squared_error: 4.9071\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 3.4097 - mean_squared_error: 3.4097 - val_loss: 4.5748 - val_mean_squared_error: 4.5748\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 3.1973 - mean_squared_error: 3.1973 - val_loss: 4.3373 - val_mean_squared_error: 4.3373\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 3.0260 - mean_squared_error: 3.0260 - val_loss: 4.1018 - val_mean_squared_error: 4.1018\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 2.8562 - mean_squared_error: 2.8562 - val_loss: 3.8190 - val_mean_squared_error: 3.8190\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 2.7312 - mean_squared_error: 2.7312 - val_loss: 3.6344 - val_mean_squared_error: 3.6344\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 2.6029 - mean_squared_error: 2.6029 - val_loss: 3.4948 - val_mean_squared_error: 3.4948\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 2.4902 - mean_squared_error: 2.4902 - val_loss: 3.3836 - val_mean_squared_error: 3.3836\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 2.3916 - mean_squared_error: 2.3916 - val_loss: 3.2795 - val_mean_squared_error: 3.2795\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 2.3117 - mean_squared_error: 2.3117 - val_loss: 3.2144 - val_mean_squared_error: 3.2144\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 2.2365 - mean_squared_error: 2.2365 - val_loss: 3.1180 - val_mean_squared_error: 3.1180\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 2.1643 - mean_squared_error: 2.1643 - val_loss: 3.0204 - val_mean_squared_error: 3.0204\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 2.0973 - mean_squared_error: 2.0973 - val_loss: 2.9308 - val_mean_squared_error: 2.9308\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 2.0319 - mean_squared_error: 2.0319 - val_loss: 2.8365 - val_mean_squared_error: 2.8365\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.9659 - mean_squared_error: 1.9659 - val_loss: 2.7495 - val_mean_squared_error: 2.7495\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.9069 - mean_squared_error: 1.9069 - val_loss: 2.6655 - val_mean_squared_error: 2.6655\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1.8505 - mean_squared_error: 1.8505 - val_loss: 2.5911 - val_mean_squared_error: 2.5911\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1.8060 - mean_squared_error: 1.8060 - val_loss: 2.5197 - val_mean_squared_error: 2.5197\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.7616 - mean_squared_error: 1.7616 - val_loss: 2.4618 - val_mean_squared_error: 2.4618\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1.7224 - mean_squared_error: 1.7224 - val_loss: 2.4080 - val_mean_squared_error: 2.4080\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.6844 - mean_squared_error: 1.6844 - val_loss: 2.3569 - val_mean_squared_error: 2.3569\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.6474 - mean_squared_error: 1.6474 - val_loss: 2.3093 - val_mean_squared_error: 2.3093\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1.6129 - mean_squared_error: 1.6129 - val_loss: 2.2576 - val_mean_squared_error: 2.2576\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.5794 - mean_squared_error: 1.5794 - val_loss: 2.2184 - val_mean_squared_error: 2.2184\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1.5487 - mean_squared_error: 1.5487 - val_loss: 2.1788 - val_mean_squared_error: 2.1788\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1.5200 - mean_squared_error: 1.5200 - val_loss: 2.1447 - val_mean_squared_error: 2.1447\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.4957 - mean_squared_error: 1.4957 - val_loss: 2.1135 - val_mean_squared_error: 2.1135\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.4713 - mean_squared_error: 1.4713 - val_loss: 2.0707 - val_mean_squared_error: 2.0707\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1.4472 - mean_squared_error: 1.4472 - val_loss: 2.0380 - val_mean_squared_error: 2.0380\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.4259 - mean_squared_error: 1.4259 - val_loss: 2.0045 - val_mean_squared_error: 2.0045\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.4005 - mean_squared_error: 1.4005 - val_loss: 1.9771 - val_mean_squared_error: 1.9771\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.3806 - mean_squared_error: 1.3806 - val_loss: 1.9503 - val_mean_squared_error: 1.9503\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1.3621 - mean_squared_error: 1.3621 - val_loss: 1.9201 - val_mean_squared_error: 1.9201\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1.3423 - mean_squared_error: 1.3423 - val_loss: 1.8969 - val_mean_squared_error: 1.8969\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.3263 - mean_squared_error: 1.3263 - val_loss: 1.8762 - val_mean_squared_error: 1.8762\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.3089 - mean_squared_error: 1.3089 - val_loss: 1.8529 - val_mean_squared_error: 1.8529\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1.2939 - mean_squared_error: 1.2939 - val_loss: 1.8313 - val_mean_squared_error: 1.8313\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.2797 - mean_squared_error: 1.2797 - val_loss: 1.8147 - val_mean_squared_error: 1.8147\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.2679 - mean_squared_error: 1.2679 - val_loss: 1.7976 - val_mean_squared_error: 1.7976\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.2551 - mean_squared_error: 1.2551 - val_loss: 1.7813 - val_mean_squared_error: 1.7813\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.2406 - mean_squared_error: 1.2406 - val_loss: 1.7669 - val_mean_squared_error: 1.7669\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.2288 - mean_squared_error: 1.2288 - val_loss: 1.7490 - val_mean_squared_error: 1.7490\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.2159 - mean_squared_error: 1.2159 - val_loss: 1.7343 - val_mean_squared_error: 1.7343\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.2049 - mean_squared_error: 1.2049 - val_loss: 1.7201 - val_mean_squared_error: 1.7201\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.1937 - mean_squared_error: 1.1937 - val_loss: 1.7059 - val_mean_squared_error: 1.7059\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.1826 - mean_squared_error: 1.1826 - val_loss: 1.6925 - val_mean_squared_error: 1.6925\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 1.1720 - mean_squared_error: 1.1720 - val_loss: 1.6811 - val_mean_squared_error: 1.6811\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.1609 - mean_squared_error: 1.1609 - val_loss: 1.6678 - val_mean_squared_error: 1.6678\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.1511 - mean_squared_error: 1.1511 - val_loss: 1.6560 - val_mean_squared_error: 1.6560\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.1445 - mean_squared_error: 1.1445 - val_loss: 1.6553 - val_mean_squared_error: 1.6553\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.1357 - mean_squared_error: 1.1357 - val_loss: 1.6435 - val_mean_squared_error: 1.6435\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.1252 - mean_squared_error: 1.1252 - val_loss: 1.6271 - val_mean_squared_error: 1.6271\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.1155 - mean_squared_error: 1.1155 - val_loss: 1.6130 - val_mean_squared_error: 1.6130\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1.1069 - mean_squared_error: 1.1069 - val_loss: 1.5993 - val_mean_squared_error: 1.5993\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0981 - mean_squared_error: 1.0981 - val_loss: 1.5878 - val_mean_squared_error: 1.5878\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.0886 - mean_squared_error: 1.0886 - val_loss: 1.5776 - val_mean_squared_error: 1.5776\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0801 - mean_squared_error: 1.0801 - val_loss: 1.5694 - val_mean_squared_error: 1.5694\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0706 - mean_squared_error: 1.0706 - val_loss: 1.5619 - val_mean_squared_error: 1.5619\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0618 - mean_squared_error: 1.0618 - val_loss: 1.5614 - val_mean_squared_error: 1.5614\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.0555 - mean_squared_error: 1.0555 - val_loss: 1.5565 - val_mean_squared_error: 1.5565\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.0484 - mean_squared_error: 1.0484 - val_loss: 1.5475 - val_mean_squared_error: 1.5475\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0428 - mean_squared_error: 1.0428 - val_loss: 1.5476 - val_mean_squared_error: 1.5476\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0358 - mean_squared_error: 1.0358 - val_loss: 1.5409 - val_mean_squared_error: 1.5409\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.0299 - mean_squared_error: 1.0299 - val_loss: 1.5303 - val_mean_squared_error: 1.5303\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0224 - mean_squared_error: 1.0224 - val_loss: 1.5184 - val_mean_squared_error: 1.5184\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.0139 - mean_squared_error: 1.0139 - val_loss: 1.5079 - val_mean_squared_error: 1.5079\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0078 - mean_squared_error: 1.0078 - val_loss: 1.4957 - val_mean_squared_error: 1.4957\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0031 - mean_squared_error: 1.0031 - val_loss: 1.4863 - val_mean_squared_error: 1.4863\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.9969 - mean_squared_error: 0.9969 - val_loss: 1.4793 - val_mean_squared_error: 1.4793\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.9908 - mean_squared_error: 0.9908 - val_loss: 1.4727 - val_mean_squared_error: 1.4727\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9861 - mean_squared_error: 0.9861 - val_loss: 1.4672 - val_mean_squared_error: 1.4672\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.9785 - mean_squared_error: 0.9785 - val_loss: 1.4570 - val_mean_squared_error: 1.4570\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.9761 - mean_squared_error: 0.9761 - val_loss: 1.4504 - val_mean_squared_error: 1.4504\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.9732 - mean_squared_error: 0.9732 - val_loss: 1.4443 - val_mean_squared_error: 1.4443\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9675 - mean_squared_error: 0.9675 - val_loss: 1.4378 - val_mean_squared_error: 1.4378\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.9594 - mean_squared_error: 0.9594 - val_loss: 1.4321 - val_mean_squared_error: 1.4321\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9536 - mean_squared_error: 0.9536 - val_loss: 1.4271 - val_mean_squared_error: 1.4271\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.9476 - mean_squared_error: 0.9476 - val_loss: 1.4231 - val_mean_squared_error: 1.4231\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9425 - mean_squared_error: 0.9425 - val_loss: 1.4186 - val_mean_squared_error: 1.4186\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.9388 - mean_squared_error: 0.9388 - val_loss: 1.4138 - val_mean_squared_error: 1.4138\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9349 - mean_squared_error: 0.9349 - val_loss: 1.4116 - val_mean_squared_error: 1.4116\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.9312 - mean_squared_error: 0.9312 - val_loss: 1.4095 - val_mean_squared_error: 1.4095\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9267 - mean_squared_error: 0.9267 - val_loss: 1.4059 - val_mean_squared_error: 1.4059\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.9215 - mean_squared_error: 0.9215 - val_loss: 1.3995 - val_mean_squared_error: 1.3995\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9177 - mean_squared_error: 0.9177 - val_loss: 1.3945 - val_mean_squared_error: 1.3945\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.9139 - mean_squared_error: 0.9139 - val_loss: 1.3911 - val_mean_squared_error: 1.3911\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.9099 - mean_squared_error: 0.9099 - val_loss: 1.3864 - val_mean_squared_error: 1.3864\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.9065 - mean_squared_error: 0.9065 - val_loss: 1.3818 - val_mean_squared_error: 1.3818\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.9027 - mean_squared_error: 0.9027 - val_loss: 1.3778 - val_mean_squared_error: 1.3778\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8985 - mean_squared_error: 0.8985 - val_loss: 1.3757 - val_mean_squared_error: 1.3757\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.8928 - mean_squared_error: 0.8928 - val_loss: 1.3715 - val_mean_squared_error: 1.3715\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8895 - mean_squared_error: 0.8895 - val_loss: 1.3680 - val_mean_squared_error: 1.3680\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.8870 - mean_squared_error: 0.8870 - val_loss: 1.3675 - val_mean_squared_error: 1.3675\n",
      "\n",
      " Evaluate the new model against the test set:\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3993 - mean_squared_error: 1.3993\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'loss': 1.3992924690246582, 'mean_squared_error': 1.3992925882339478}"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.00010\n",
    "epochs = 100\n",
    "batch_size = 20\n",
    "\n",
    "# Specify the label\n",
    "label_name = \"BodyFat\"\n",
    "\n",
    "# Split the original training set into a reduced training set and a\n",
    "# validation set.\n",
    "validation_split = 0.2\n",
    "\n",
    "dnn_outputs = get_outputs_dnn()\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(\n",
    "    inputs,\n",
    "    dnn_outputs,\n",
    "    learning_rate)\n",
    "\n",
    "# Train the model on the normalized training set. We're passing the entire\n",
    "# normalized training set, but the model will only use the features\n",
    "# defined in our inputs.\n",
    "epochs = train_model(my_model, trainDF, epochs,\n",
    "                                   batch_size, label_name, validation_split)\n",
    "\n",
    "# After building a model against the training set, test that model\n",
    "# against the test set.\n",
    "test_features = {name:np.array(value) for name, value in testDF.items()}\n",
    "test_label = test_bodyfat_normalized(np.array(test_features.pop(label_name))) # isolate the label\n",
    "\n",
    "print(\"\\n Evaluate the new model against the test set:\")\n",
    "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size, return_dict=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[126], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#output predicted vs correct\u001B[39;00m\n\u001B[0;32m      2\u001B[0m results \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRow\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPredicted Body Fat\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCorrect Body Fat\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m----> 3\u001B[0m mean \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_bodyfat_normalized\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m      4\u001B[0m variance \u001B[38;5;241m=\u001B[39m train_bodyfat_normalized\u001B[38;5;241m.\u001B[39mvar()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, row \u001B[38;5;129;01min\u001B[39;00m testDF\u001B[38;5;241m.\u001B[39miterrows():\n",
      "\u001B[1;31mTypeError\u001B[0m: 'tensorflow.python.framework.ops.EagerTensor' object is not callable"
     ]
    }
   ],
   "source": [
    "#output predicted vs correct\n",
    "results = pd.DataFrame(columns=['Row', 'Predicted Body Fat', 'Correct Body Fat'])\n",
    "mean = train_bodyfat_normalized.mean().numpy()\n",
    "variance = train_bodyfat_normalized.var().numpy()\n",
    "\n",
    "for index, row in testDF.iterrows():\n",
    "    test_features = {name: np.array([value]) for name, value in row.items()}\n",
    "    correct_label = np.array([row[label_name]])\n",
    "    correct_label_normalized = (correct_label - mean) / np.sqrt(variance)\n",
    "    predictions = my_model.predict(test_features, verbose=0)\n",
    "    predicted_bodyfat_normalized = predictions['dense_output'][0][0]\n",
    "    predicted_bodyfat = (predicted_bodyfat_normalized * np.sqrt(variance)) + mean\n",
    "    predicted_bodyfat = np.round(predicted_bodyfat, decimals=1)\n",
    "    actual_bodyfat = (correct_label_normalized * np.sqrt(variance)) + mean\n",
    "    results = results.append({'Row': index, 'Predicted Body Fat': predicted_bodyfat[0], 'Correct Body Fat': actual_bodyfat[0]}, ignore_index=True)\n",
    "\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
