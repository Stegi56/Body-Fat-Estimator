{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Imported modules.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "print(\"Imported modules.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set loaded. Num examples:  252\n",
      "Made training and test sets\n"
     ]
    },
    {
     "data": {
      "text/plain": "     Density  BodyFat  Age  Weight  Height  Neck  Chest  Abdomen   Hip  Thigh  \\\n200     1.07    12.20   43  178.25   70.25 37.80 102.70    89.20 99.20  60.20   \n68      1.08     6.30   54  155.25   69.25 37.50  89.30    78.40 96.10  56.00   \n85      1.04    26.60   67  167.00   67.50 36.50  98.90    89.70 96.20  54.70   \n153     1.06    16.50   27  156.75   67.25 37.90  94.00    88.20 95.20  56.80   \n219     1.06    15.00   53  154.50   69.25 37.60  93.90    88.70 94.50  53.70   \n..       ...      ...  ...     ...     ...   ...    ...      ...   ...    ...   \n71      1.08     8.80   55  146.75   68.75 38.70  88.50    82.80 95.50  58.90   \n129     1.06    14.90   42  165.25   69.75 38.30  96.20    87.00 97.80  57.40   \n198     1.08     6.60   42  167.25   72.75 37.60  94.00    78.00 99.00  57.50   \n133     1.04    26.10   50  157.00   66.75 37.80 100.40    89.40 92.30  56.10   \n46      1.07    10.80   40  133.50   67.50 33.60  88.20    73.70 88.50  53.30   \n\n     Knee  Ankle  Biceps  Forearm  Wrist  \n200 39.20  23.80   31.70    28.40  18.60  \n68  37.40  22.40   32.60    28.10  18.10  \n85  37.80  33.70   32.40    27.70  18.20  \n153 37.40  22.80   30.60    28.30  17.90  \n219 36.20  22.00   28.50    25.70  17.10  \n..    ...    ...     ...      ...    ...  \n71  37.60  21.60   30.30    27.30  18.30  \n129 36.90  22.20   31.60    27.80  17.70  \n198 40.00  22.50   30.60    30.00  18.50  \n133 35.60  20.50   33.60    29.30  17.30  \n46  34.50  22.50   27.90    26.20  17.30  \n\n[252 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Density</th>\n      <th>BodyFat</th>\n      <th>Age</th>\n      <th>Weight</th>\n      <th>Height</th>\n      <th>Neck</th>\n      <th>Chest</th>\n      <th>Abdomen</th>\n      <th>Hip</th>\n      <th>Thigh</th>\n      <th>Knee</th>\n      <th>Ankle</th>\n      <th>Biceps</th>\n      <th>Forearm</th>\n      <th>Wrist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>200</th>\n      <td>1.07</td>\n      <td>12.20</td>\n      <td>43</td>\n      <td>178.25</td>\n      <td>70.25</td>\n      <td>37.80</td>\n      <td>102.70</td>\n      <td>89.20</td>\n      <td>99.20</td>\n      <td>60.20</td>\n      <td>39.20</td>\n      <td>23.80</td>\n      <td>31.70</td>\n      <td>28.40</td>\n      <td>18.60</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>1.08</td>\n      <td>6.30</td>\n      <td>54</td>\n      <td>155.25</td>\n      <td>69.25</td>\n      <td>37.50</td>\n      <td>89.30</td>\n      <td>78.40</td>\n      <td>96.10</td>\n      <td>56.00</td>\n      <td>37.40</td>\n      <td>22.40</td>\n      <td>32.60</td>\n      <td>28.10</td>\n      <td>18.10</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>1.04</td>\n      <td>26.60</td>\n      <td>67</td>\n      <td>167.00</td>\n      <td>67.50</td>\n      <td>36.50</td>\n      <td>98.90</td>\n      <td>89.70</td>\n      <td>96.20</td>\n      <td>54.70</td>\n      <td>37.80</td>\n      <td>33.70</td>\n      <td>32.40</td>\n      <td>27.70</td>\n      <td>18.20</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>1.06</td>\n      <td>16.50</td>\n      <td>27</td>\n      <td>156.75</td>\n      <td>67.25</td>\n      <td>37.90</td>\n      <td>94.00</td>\n      <td>88.20</td>\n      <td>95.20</td>\n      <td>56.80</td>\n      <td>37.40</td>\n      <td>22.80</td>\n      <td>30.60</td>\n      <td>28.30</td>\n      <td>17.90</td>\n    </tr>\n    <tr>\n      <th>219</th>\n      <td>1.06</td>\n      <td>15.00</td>\n      <td>53</td>\n      <td>154.50</td>\n      <td>69.25</td>\n      <td>37.60</td>\n      <td>93.90</td>\n      <td>88.70</td>\n      <td>94.50</td>\n      <td>53.70</td>\n      <td>36.20</td>\n      <td>22.00</td>\n      <td>28.50</td>\n      <td>25.70</td>\n      <td>17.10</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>1.08</td>\n      <td>8.80</td>\n      <td>55</td>\n      <td>146.75</td>\n      <td>68.75</td>\n      <td>38.70</td>\n      <td>88.50</td>\n      <td>82.80</td>\n      <td>95.50</td>\n      <td>58.90</td>\n      <td>37.60</td>\n      <td>21.60</td>\n      <td>30.30</td>\n      <td>27.30</td>\n      <td>18.30</td>\n    </tr>\n    <tr>\n      <th>129</th>\n      <td>1.06</td>\n      <td>14.90</td>\n      <td>42</td>\n      <td>165.25</td>\n      <td>69.75</td>\n      <td>38.30</td>\n      <td>96.20</td>\n      <td>87.00</td>\n      <td>97.80</td>\n      <td>57.40</td>\n      <td>36.90</td>\n      <td>22.20</td>\n      <td>31.60</td>\n      <td>27.80</td>\n      <td>17.70</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>1.08</td>\n      <td>6.60</td>\n      <td>42</td>\n      <td>167.25</td>\n      <td>72.75</td>\n      <td>37.60</td>\n      <td>94.00</td>\n      <td>78.00</td>\n      <td>99.00</td>\n      <td>57.50</td>\n      <td>40.00</td>\n      <td>22.50</td>\n      <td>30.60</td>\n      <td>30.00</td>\n      <td>18.50</td>\n    </tr>\n    <tr>\n      <th>133</th>\n      <td>1.04</td>\n      <td>26.10</td>\n      <td>50</td>\n      <td>157.00</td>\n      <td>66.75</td>\n      <td>37.80</td>\n      <td>100.40</td>\n      <td>89.40</td>\n      <td>92.30</td>\n      <td>56.10</td>\n      <td>35.60</td>\n      <td>20.50</td>\n      <td>33.60</td>\n      <td>29.30</td>\n      <td>17.30</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>1.07</td>\n      <td>10.80</td>\n      <td>40</td>\n      <td>133.50</td>\n      <td>67.50</td>\n      <td>33.60</td>\n      <td>88.20</td>\n      <td>73.70</td>\n      <td>88.50</td>\n      <td>53.30</td>\n      <td>34.50</td>\n      <td>22.50</td>\n      <td>27.90</td>\n      <td>26.20</td>\n      <td>17.30</td>\n    </tr>\n  </tbody>\n</table>\n<p>252 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataFrame = pd.read_csv(\"bodyfat.csv\")\n",
    "dataFrame = dataFrame.reindex(np.random.permutation(dataFrame.index))\n",
    "\n",
    "print(\"Data set loaded. Num examples: \", len(dataFrame))\n",
    "\n",
    "trainDF = dataFrame.sample(frac = 0.8)\n",
    "testDF = dataFrame.drop(trainDF.index)\n",
    "\n",
    "print(\"Made training and test sets\")\n",
    "\n",
    "dataFrame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing layers defined.\n"
     ]
    }
   ],
   "source": [
    "# Keras Input tensors of float values.\n",
    "inputs = {\n",
    "    'Density':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Density'),\n",
    "    'Age':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Age'),\n",
    "    'Weight':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Weight'),\n",
    "    'Height':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Height'),\n",
    "    'Neck':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Neck'),\n",
    "    'Chest':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Chest'),\n",
    "    'Abdomen':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Abdomen'),\n",
    "    'Hip':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Hip'),\n",
    "    'Thigh':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Thigh'),\n",
    "    'Knee':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Knee'),\n",
    "    'Ankle':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Ankle'),\n",
    "    'Biceps':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Biceps'),\n",
    "    'Forearm':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Forearm'),\n",
    "    'Wrist':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='Wrist')\n",
    "}\n",
    "\n",
    "#Normalise\n",
    "density = tf.keras.layers.Normalization(\n",
    "    name='normalization_density',\n",
    "    axis=None)\n",
    "density.adapt(trainDF['Density'])\n",
    "density = density(inputs['Density'])\n",
    "\n",
    "age = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_age',\n",
    "    axis=None)\n",
    "age.adapt(trainDF['Age'])\n",
    "age = age(inputs.get('Age'))\n",
    "\n",
    "weight = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_weight',\n",
    "    axis=None)\n",
    "weight.adapt(trainDF['Weight'])\n",
    "weight = weight(inputs.get('Weight'))\n",
    "\n",
    "height = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_height',\n",
    "    axis=None)\n",
    "height.adapt(trainDF['Height'])\n",
    "height = height(inputs.get('Height'))\n",
    "\n",
    "neck = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_neck',\n",
    "    axis=None)\n",
    "neck.adapt(trainDF['Neck'])\n",
    "neck = neck(inputs.get('Neck'))\n",
    "\n",
    "chest = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_chest',\n",
    "    axis=None)\n",
    "chest.adapt(trainDF['Chest'])\n",
    "chest = chest(inputs.get('Chest'))\n",
    "\n",
    "abdomen = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_abdomen',\n",
    "    axis=None)\n",
    "abdomen.adapt(trainDF['Abdomen'])\n",
    "abdomen = abdomen(inputs.get('Abdomen'))\n",
    "\n",
    "hip = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_hip',\n",
    "    axis=None)\n",
    "hip.adapt(trainDF['Hip'])\n",
    "hip = hip(inputs.get('Hip'))\n",
    "\n",
    "thigh = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_thigh',\n",
    "    axis=None)\n",
    "thigh.adapt(trainDF['Thigh'])\n",
    "thigh = thigh(inputs.get('Thigh'))\n",
    "\n",
    "knee = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_knee',\n",
    "    axis=None)\n",
    "knee.adapt(trainDF['Knee'])\n",
    "knee = knee(inputs.get('Knee'))\n",
    "\n",
    "ankle = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_ankle',\n",
    "    axis=None)\n",
    "ankle.adapt(trainDF['Ankle'])\n",
    "ankle = ankle(inputs.get('Ankle'))\n",
    "\n",
    "biceps = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_biceps',\n",
    "    axis=None)\n",
    "biceps.adapt(trainDF['Biceps'])\n",
    "biceps = biceps(inputs.get('Biceps'))\n",
    "\n",
    "forearm = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_forearm',\n",
    "    axis=None)\n",
    "forearm.adapt(trainDF['Forearm'])\n",
    "forearm = forearm(inputs.get('Forearm'))\n",
    "\n",
    "wrist = tf.keras.layers.Normalization(\n",
    "    name = 'normalization_wrist',\n",
    "    axis=None)\n",
    "wrist.adapt(trainDF['Wrist'])\n",
    "wrist = wrist(inputs.get('Wrist'))\n",
    "\n",
    "# Concatenate our inputs into a single tensor.\n",
    "preprocessing_layers = tf.keras.layers.Concatenate()\n",
    "preprocessing_layers = preprocessing_layers(list(inputs.values()))\n",
    "\n",
    "print(\"Preprocessing layers defined.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the create_model and train_model functions.\n"
     ]
    }
   ],
   "source": [
    "#@title Define functions to create and train a linear regression model\n",
    "def create_model(my_inputs, my_outputs, my_learning_rate):\n",
    "    \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "    model = tf.keras.Model(inputs=my_inputs, outputs=my_outputs)\n",
    "\n",
    "    # Construct the layers into a model that TensorFlow can execute.\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "        learning_rate=my_learning_rate),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create Normalization layers to normalize the median_house_value data.\n",
    "# Because median_house_value is our label (i.e., the target value we're\n",
    "# predicting), these layers won't be added to our model.\n",
    "train_bodyfat_normalized = tf.keras.layers.Normalization(axis=None)\n",
    "train_bodyfat_normalized.adapt(\n",
    "np.array(trainDF['BodyFat']))\n",
    "\n",
    "test_bodyfat_normalized = tf.keras.layers.Normalization(axis=None)\n",
    "test_bodyfat_normalized.adapt(\n",
    "np.array(testDF['BodyFat']))\n",
    "\n",
    "def train_model(model, dataset, epochs, batch_size, label_name, validation_split=0.1):\n",
    "    \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
    "\n",
    "    # Split the dataset into features and label.\n",
    "    features = {name:np.array(value) for name, value in dataset.items()}\n",
    "    label = train_bodyfat_normalized(\n",
    "        np.array(features.pop(label_name)))\n",
    "\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                        epochs=epochs, shuffle=True, validation_split=validation_split, callbacks=[tensorboard_callback])\n",
    "\n",
    "    # Get details that will be useful for plotting the loss curve.\\n\",\n",
    "    epochs = history.epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    mse = hist[\"mean_squared_error\"]\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    return epochs, mse, history.history\n",
    "\n",
    "\n",
    "print(\"Defined the create_model and train_model functions.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#@title Define linear regression model outputs\n",
    "def get_outputs_linear_regression():\n",
    "    # Create the Dense output layer.\n",
    "    dense_output = tf.keras.layers.Dense(units=1, input_shape=(1,),\n",
    "                                         name='dense_output')(preprocessing_layers)\n",
    "\n",
    "    # Define an output dictionary we'll send to the model constructor.\n",
    "    outputs = {\n",
    "        'dense_output': dense_output\n",
    "    }\n",
    "    return outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_outputs_dnn():\n",
    "    # Create a Dense layer with 20 nodes.\n",
    "    dense_output = tf.keras.layers.Dense(units=13, input_shape=(1,),\n",
    "                                         activation='relu',\n",
    "                                         name='hidden_dense_layer_1')(preprocessing_layers)\n",
    "    # Create a Dense layer with 12 nodes.\n",
    "    dense_output = tf.keras.layers.Dense(units=10, input_shape=(1,),\n",
    "                                         activation='relu',\n",
    "                                         name='hidden_dense_layer_2')(dense_output)\n",
    "    # Create a Dense layer with 12 nodes.\n",
    "    dense_output = tf.keras.layers.Dense(units=7, input_shape=(1,),\n",
    "                                         activation='relu',\n",
    "                                         name='hidden_dense_layer_3')(dense_output)\n",
    "    # Create a Dense layer with 12 nodes.\n",
    "    dense_output = tf.keras.layers.Dense(units=5, input_shape=(1,),\n",
    "                                         activation='relu',\n",
    "                                         name='hidden_dense_layer_4')(dense_output)\n",
    "    # Create a Dense layer with 12 nodes.\n",
    "    dense_output = tf.keras.layers.Dense(units=3, input_shape=(1,),\n",
    "                                         activation='relu',\n",
    "                                         name='hidden_dense_layer_5')(dense_output)\n",
    "    # Create the Dense output layer.\n",
    "    dense_output = tf.keras.layers.Dense(units=1, input_shape=(1,),\n",
    "                                         name='dense_output')(dense_output)\n",
    "\n",
    "    # Define an output dictionary we'll send to the model constructor.\n",
    "    outputs = {\n",
    "        'dense_output': dense_output\n",
    "    }\n",
    "\n",
    "    return outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 2s 67ms/step - loss: 5.9139 - mean_squared_error: 5.9139 - val_loss: 4.4979 - val_mean_squared_error: 4.4979\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 4.8615 - mean_squared_error: 4.8615 - val_loss: 3.7297 - val_mean_squared_error: 3.7297\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 4.0437 - mean_squared_error: 4.0437 - val_loss: 3.1409 - val_mean_squared_error: 3.1409\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 3.4592 - mean_squared_error: 3.4592 - val_loss: 2.6772 - val_mean_squared_error: 2.6772\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 3.0677 - mean_squared_error: 3.0677 - val_loss: 2.3597 - val_mean_squared_error: 2.3597\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 2.8467 - mean_squared_error: 2.8467 - val_loss: 2.1830 - val_mean_squared_error: 2.1830\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 25ms/step - loss: 2.6908 - mean_squared_error: 2.6908 - val_loss: 2.0651 - val_mean_squared_error: 2.0651\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 2.5643 - mean_squared_error: 2.5643 - val_loss: 1.9846 - val_mean_squared_error: 1.9846\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 2.4849 - mean_squared_error: 2.4849 - val_loss: 1.9267 - val_mean_squared_error: 1.9267\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 2.4122 - mean_squared_error: 2.4122 - val_loss: 1.8655 - val_mean_squared_error: 1.8655\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 2.3514 - mean_squared_error: 2.3514 - val_loss: 1.8097 - val_mean_squared_error: 1.8097\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 2.2884 - mean_squared_error: 2.2884 - val_loss: 1.7498 - val_mean_squared_error: 1.7498\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 2.2665 - mean_squared_error: 2.2665 - val_loss: 1.7849 - val_mean_squared_error: 1.7849\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 2.2541 - mean_squared_error: 2.2541 - val_loss: 1.7336 - val_mean_squared_error: 1.7336\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 2.1851 - mean_squared_error: 2.1851 - val_loss: 1.6361 - val_mean_squared_error: 1.6361\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 2.1135 - mean_squared_error: 2.1135 - val_loss: 1.5575 - val_mean_squared_error: 1.5575\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 2.0465 - mean_squared_error: 2.0465 - val_loss: 1.5023 - val_mean_squared_error: 1.5023\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.9722 - mean_squared_error: 1.9722 - val_loss: 1.4386 - val_mean_squared_error: 1.4386\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.8933 - mean_squared_error: 1.8933 - val_loss: 1.3485 - val_mean_squared_error: 1.3485\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.8047 - mean_squared_error: 1.8047 - val_loss: 1.2622 - val_mean_squared_error: 1.2622\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.7429 - mean_squared_error: 1.7429 - val_loss: 1.2053 - val_mean_squared_error: 1.2053\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.6923 - mean_squared_error: 1.6923 - val_loss: 1.1628 - val_mean_squared_error: 1.1628\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.6478 - mean_squared_error: 1.6478 - val_loss: 1.1205 - val_mean_squared_error: 1.1205\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.5991 - mean_squared_error: 1.5991 - val_loss: 1.0868 - val_mean_squared_error: 1.0868\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 1.5592 - mean_squared_error: 1.5592 - val_loss: 1.0619 - val_mean_squared_error: 1.0619\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.5216 - mean_squared_error: 1.5216 - val_loss: 1.0375 - val_mean_squared_error: 1.0375\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 1.4722 - mean_squared_error: 1.4722 - val_loss: 0.9976 - val_mean_squared_error: 0.9976\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 1.4096 - mean_squared_error: 1.4096 - val_loss: 0.9597 - val_mean_squared_error: 0.9597\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 26ms/step - loss: 1.3421 - mean_squared_error: 1.3421 - val_loss: 0.9320 - val_mean_squared_error: 0.9320\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 1.2926 - mean_squared_error: 1.2926 - val_loss: 0.9034 - val_mean_squared_error: 0.9034\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 1.2405 - mean_squared_error: 1.2405 - val_loss: 0.8813 - val_mean_squared_error: 0.8813\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 1.2035 - mean_squared_error: 1.2035 - val_loss: 0.8683 - val_mean_squared_error: 0.8683\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 1.1801 - mean_squared_error: 1.1801 - val_loss: 0.8446 - val_mean_squared_error: 0.8446\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 1.1573 - mean_squared_error: 1.1573 - val_loss: 0.8378 - val_mean_squared_error: 0.8378\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 1.1467 - mean_squared_error: 1.1467 - val_loss: 0.8375 - val_mean_squared_error: 0.8375\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 1.1397 - mean_squared_error: 1.1397 - val_loss: 0.8332 - val_mean_squared_error: 0.8332\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 1.1289 - mean_squared_error: 1.1289 - val_loss: 0.8235 - val_mean_squared_error: 0.8235\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.1257 - mean_squared_error: 1.1257 - val_loss: 0.8544 - val_mean_squared_error: 0.8544\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 1.1249 - mean_squared_error: 1.1249 - val_loss: 0.8627 - val_mean_squared_error: 0.8627\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 1.1212 - mean_squared_error: 1.1212 - val_loss: 0.8580 - val_mean_squared_error: 0.8580\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.1055 - mean_squared_error: 1.1055 - val_loss: 0.8337 - val_mean_squared_error: 0.8337\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 1.0902 - mean_squared_error: 1.0902 - val_loss: 0.8144 - val_mean_squared_error: 0.8144\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 1.0804 - mean_squared_error: 1.0804 - val_loss: 0.7914 - val_mean_squared_error: 0.7914\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 1.0705 - mean_squared_error: 1.0705 - val_loss: 0.7812 - val_mean_squared_error: 0.7812\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 1.0684 - mean_squared_error: 1.0684 - val_loss: 0.7707 - val_mean_squared_error: 0.7707\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 1.0652 - mean_squared_error: 1.0652 - val_loss: 0.7672 - val_mean_squared_error: 0.7672\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 1.0638 - mean_squared_error: 1.0638 - val_loss: 0.7597 - val_mean_squared_error: 0.7597\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 1.0631 - mean_squared_error: 1.0631 - val_loss: 0.7583 - val_mean_squared_error: 0.7583\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 1.0623 - mean_squared_error: 1.0623 - val_loss: 0.7621 - val_mean_squared_error: 0.7621\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 1.0590 - mean_squared_error: 1.0590 - val_loss: 0.7624 - val_mean_squared_error: 0.7624\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 1.0568 - mean_squared_error: 1.0568 - val_loss: 0.7637 - val_mean_squared_error: 0.7637\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 1.0546 - mean_squared_error: 1.0546 - val_loss: 0.7641 - val_mean_squared_error: 0.7641\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 1.0514 - mean_squared_error: 1.0514 - val_loss: 0.7641 - val_mean_squared_error: 0.7641\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 1.0477 - mean_squared_error: 1.0477 - val_loss: 0.7668 - val_mean_squared_error: 0.7668\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 1.0457 - mean_squared_error: 1.0457 - val_loss: 0.7663 - val_mean_squared_error: 0.7663\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 1.0443 - mean_squared_error: 1.0443 - val_loss: 0.7685 - val_mean_squared_error: 0.7685\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 1.0420 - mean_squared_error: 1.0420 - val_loss: 0.7673 - val_mean_squared_error: 0.7673\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 1.0402 - mean_squared_error: 1.0402 - val_loss: 0.7682 - val_mean_squared_error: 0.7682\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 1.0393 - mean_squared_error: 1.0393 - val_loss: 0.7696 - val_mean_squared_error: 0.7696\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 1.0380 - mean_squared_error: 1.0380 - val_loss: 0.7719 - val_mean_squared_error: 0.7719\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 1.0365 - mean_squared_error: 1.0365 - val_loss: 0.7728 - val_mean_squared_error: 0.7728\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 1.0355 - mean_squared_error: 1.0355 - val_loss: 0.7720 - val_mean_squared_error: 0.7720\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 1.0343 - mean_squared_error: 1.0343 - val_loss: 0.7729 - val_mean_squared_error: 0.7729\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0328 - mean_squared_error: 1.0328 - val_loss: 0.7739 - val_mean_squared_error: 0.7739\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 1.0299 - mean_squared_error: 1.0299 - val_loss: 0.7736 - val_mean_squared_error: 0.7736\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 1.0272 - mean_squared_error: 1.0272 - val_loss: 0.7751 - val_mean_squared_error: 0.7751\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 1.0262 - mean_squared_error: 1.0262 - val_loss: 0.7782 - val_mean_squared_error: 0.7782\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 1.0233 - mean_squared_error: 1.0233 - val_loss: 0.7802 - val_mean_squared_error: 0.7802\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 1.0203 - mean_squared_error: 1.0203 - val_loss: 0.7805 - val_mean_squared_error: 0.7805\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.0187 - mean_squared_error: 1.0187 - val_loss: 0.7823 - val_mean_squared_error: 0.7823\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1.0167 - mean_squared_error: 1.0167 - val_loss: 0.7852 - val_mean_squared_error: 0.7852\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 1.0143 - mean_squared_error: 1.0143 - val_loss: 0.7872 - val_mean_squared_error: 0.7872\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1.0122 - mean_squared_error: 1.0122 - val_loss: 0.7893 - val_mean_squared_error: 0.7893\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.0100 - mean_squared_error: 1.0100 - val_loss: 0.7904 - val_mean_squared_error: 0.7904\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 1.0081 - mean_squared_error: 1.0081 - val_loss: 0.7921 - val_mean_squared_error: 0.7921\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 1.0067 - mean_squared_error: 1.0067 - val_loss: 0.7937 - val_mean_squared_error: 0.7937\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 31ms/step - loss: 1.0052 - mean_squared_error: 1.0052 - val_loss: 0.7948 - val_mean_squared_error: 0.7948\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 1.0037 - mean_squared_error: 1.0037 - val_loss: 0.7948 - val_mean_squared_error: 0.7948\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 1.0026 - mean_squared_error: 1.0026 - val_loss: 0.7939 - val_mean_squared_error: 0.7939\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 1.0053 - mean_squared_error: 1.0053 - val_loss: 0.7803 - val_mean_squared_error: 0.7803\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 1.0043 - mean_squared_error: 1.0043 - val_loss: 0.7837 - val_mean_squared_error: 0.7837\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.9998 - mean_squared_error: 0.9998 - val_loss: 0.7845 - val_mean_squared_error: 0.7845\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.9986 - mean_squared_error: 0.9986 - val_loss: 0.7861 - val_mean_squared_error: 0.7861\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.9977 - mean_squared_error: 0.9977 - val_loss: 0.7878 - val_mean_squared_error: 0.7878\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.9969 - mean_squared_error: 0.9969 - val_loss: 0.7886 - val_mean_squared_error: 0.7886\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 0.9966 - mean_squared_error: 0.9966 - val_loss: 0.7897 - val_mean_squared_error: 0.7897\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 0.9960 - mean_squared_error: 0.9960 - val_loss: 0.7879 - val_mean_squared_error: 0.7879\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.9958 - mean_squared_error: 0.9958 - val_loss: 0.7774 - val_mean_squared_error: 0.7774\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.9981 - mean_squared_error: 0.9981 - val_loss: 0.7779 - val_mean_squared_error: 0.7779\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 0.9962 - mean_squared_error: 0.9962 - val_loss: 0.7827 - val_mean_squared_error: 0.7827\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 0.9950 - mean_squared_error: 0.9950 - val_loss: 0.7863 - val_mean_squared_error: 0.7863\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.9944 - mean_squared_error: 0.9944 - val_loss: 0.7879 - val_mean_squared_error: 0.7879\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.9939 - mean_squared_error: 0.9939 - val_loss: 0.7884 - val_mean_squared_error: 0.7884\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.9937 - mean_squared_error: 0.9937 - val_loss: 0.7888 - val_mean_squared_error: 0.7888\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.9933 - mean_squared_error: 0.9933 - val_loss: 0.7888 - val_mean_squared_error: 0.7888\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.9932 - mean_squared_error: 0.9932 - val_loss: 0.7887 - val_mean_squared_error: 0.7887\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.9931 - mean_squared_error: 0.9931 - val_loss: 0.7889 - val_mean_squared_error: 0.7889\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.9930 - mean_squared_error: 0.9930 - val_loss: 0.7890 - val_mean_squared_error: 0.7890\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.9929 - mean_squared_error: 0.9929 - val_loss: 0.7890 - val_mean_squared_error: 0.7890\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.9929 - mean_squared_error: 0.9929 - val_loss: 0.7890 - val_mean_squared_error: 0.7890\n",
      "\n",
      " Evaluate the new model against the test set:\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.3663 - mean_squared_error: 1.3663\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'loss': 1.3662856817245483, 'mean_squared_error': 1.3662856817245483}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.00010\n",
    "epochs = 100\n",
    "batch_size = 20\n",
    "\n",
    "# Specify the label\n",
    "label_name = \"BodyFat\"\n",
    "\n",
    "# Split the original training set into a reduced training set and a\n",
    "# validation set.\n",
    "validation_split = 0.2\n",
    "\n",
    "dnn_outputs = get_outputs_dnn()\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(\n",
    "    inputs,\n",
    "    dnn_outputs,\n",
    "    learning_rate)\n",
    "\n",
    "# Train the model on the normalized training set. We're passing the entire\n",
    "# normalized training set, but the model will only use the features\n",
    "# defined in our inputs.\n",
    "epochs = train_model(my_model, trainDF, epochs,\n",
    "                                   batch_size, label_name, validation_split)\n",
    "\n",
    "# After building a model against the training set, test that model\n",
    "# against the test set.\n",
    "test_features = {name:np.array(value) for name, value in testDF.items()}\n",
    "test_label = test_bodyfat_normalized(np.array(test_features.pop(label_name))) # isolate the label\n",
    "\n",
    "print(\"\\n Evaluate the new model against the test set:\")\n",
    "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size, return_dict=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#output predicted vs correct\u001B[39;00m\n\u001B[0;32m      2\u001B[0m results \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRow\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPredicted Body Fat\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCorrect Body Fat\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m----> 3\u001B[0m mean \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_bodyfat_normalized\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m      4\u001B[0m variance \u001B[38;5;241m=\u001B[39m train_bodyfat_normalized\u001B[38;5;241m.\u001B[39mvar()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, row \u001B[38;5;129;01min\u001B[39;00m testDF\u001B[38;5;241m.\u001B[39miterrows():\n",
      "\u001B[1;31mTypeError\u001B[0m: 'tensorflow.python.framework.ops.EagerTensor' object is not callable"
     ]
    }
   ],
   "source": [
    "#output predicted vs correct\n",
    "results = pd.DataFrame(columns=['Row', 'Predicted Body Fat', 'Correct Body Fat'])\n",
    "mean = train_bodyfat_normalized.mean().numpy()\n",
    "variance = train_bodyfat_normalized.var().numpy()\n",
    "\n",
    "for index, row in testDF.iterrows():\n",
    "    test_features = {name: np.array([value]) for name, value in row.items()}\n",
    "    correct_label = np.array([row[label_name]])\n",
    "    correct_label_normalized = (correct_label - mean) / np.sqrt(variance)\n",
    "    predictions = my_model.predict(test_features, verbose=0)\n",
    "    predicted_bodyfat_normalized = predictions['dense_output'][0][0]\n",
    "    predicted_bodyfat = (predicted_bodyfat_normalized * np.sqrt(variance)) + mean\n",
    "    predicted_bodyfat = np.round(predicted_bodyfat, decimals=1)\n",
    "    actual_bodyfat = (correct_label_normalized * np.sqrt(variance)) + mean\n",
    "    results = results.append({'Row': index, 'Predicted Body Fat': predicted_bodyfat[0], 'Correct Body Fat': actual_bodyfat[0]}, ignore_index=True)\n",
    "\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
